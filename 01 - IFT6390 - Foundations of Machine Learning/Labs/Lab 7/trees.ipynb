{"nbformat":4,"nbformat_minor":0,"metadata":{"anaconda-cloud":{},"colab":{"name":"trees.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"},"nav_menu":{},"toc":{"navigate_menu":true,"number_sections":true,"sideBar":true,"threshold":6,"toc_cell":false,"toc_section_display":"block","toc_window_display":false}},"cells":[{"cell_type":"markdown","metadata":{"colab_type":"text","id":"KM9XVDmL2SoT"},"source":["# Demo 10 : Decision üå≥s\n","\n","\n","\n","In this demo, you will implement:\n","- training a decision tree\n","- different methods for training a random forest\n","\n","/\n","\n","Dans ce labo, nous allons impl√©menter:\n","\n","*   l'entrainement d'un arbre de d√©cision\n","*   diff√©rentes m√©thodes pour entrainement une for√™t al√©atoire"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"xwafc_T22Soe"},"source":["## Prepare the data\n","\n","We will use the Iris dataset again. Start by loading the data and splitting it into train/test sets.\n","\n","/\n","\n","## Preparation des donn√©es\n","Nous allons encore utiliser le dataset Iris. Commencez par charger les donn√©es et les s√©parer en ensemble d'entrainement/test"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"WlNPne7V2So6","scrolled":true,"outputId":"86551884-1e9e-426d-86fe-138e36e5087d","executionInfo":{"status":"ok","timestamp":1573699697960,"user_tz":300,"elapsed":1143,"user":{"displayName":"Ioannis Mitliagkas","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mARrYotv-n8ZDKjMjlKZFJrnBCnATEt_QFIq0GBMw=s64","userId":"10798961238703719281"}},"colab":{"base_uri":"https://localhost:8080/","height":52}},"source":["import sklearn\n","import numpy as np\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","from sklearn import datasets\n","\n","iris = datasets.load_iris()\n","\n","# Split into train/test\n","# S√©pare en entrainement/test\n","from sklearn.model_selection import train_test_split\n","\n","(iris_train_x, iris_test_x, \n"," iris_train_y, iris_test_y) = train_test_split(iris.data, iris.target, test_size=100)\n","\n","print(iris_train_x.shape)\n","print(iris_test_x.shape)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["(50, 4)\n","(100, 4)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"g2xbeZdm2So5"},"source":["## Decision tree\n","\n","To implement the basic decision tree, we will first implement some helper functions.\n","\n","/\n","\n","## Arbre de d√©cision\n","Pour impl√©menter un arbre de d√©cision basique, nous devons d'abord cr√©er quelques fonctions utiles."]},{"cell_type":"code","metadata":{"id":"XNdrhTYhglQ4","colab_type":"code","outputId":"a5f9b2a4-d960-4a0c-e8ab-d5c1c8c97b38","executionInfo":{"status":"ok","timestamp":1573699700292,"user_tz":300,"elapsed":358,"user":{"displayName":"Ioannis Mitliagkas","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mARrYotv-n8ZDKjMjlKZFJrnBCnATEt_QFIq0GBMw=s64","userId":"10798961238703719281"}},"colab":{"base_uri":"https://localhost:8080/","height":52}},"source":["from collections import Counter\n","\n","def get_majority_class(labels):\n","    # This function should return the most common label\n","    # in the input array.\n","    #\n","    # Cette fonction doit retourner le label le plus\n","    # fr√©quent dans le tableau d'entr√©e.\n","    pass\n","\n","def compute_entropy(labels):\n","    # This function should compute the entropy\n","    # (= sum_l(-p_l log2 (p_l)) for each label l)\n","    # of the input array.\n","    #\n","    # Cette fonction doit retourner l'entropie\n","    # (= sum_l(-p_l log2 (p_l)) pour chaque label l)\n","    # du tableau d'entr√©e\n","    pass\n","\n","example_labels = np.array([3,1,2,0,2])\n","print(get_majority_class(example_labels)) # should be 2\n","print(compute_entropy(example_labels)) # should be 1.9219280948873623"],"execution_count":0,"outputs":[{"output_type":"stream","text":["None\n","None\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"kh7WIMBwglQ7","colab_type":"text"},"source":["Let's write a **Node** class to use in the decision tree. A node in the tree can:\n","- ask a question (= determine whether examples have a certain feature greater than a certain threshold),\n","- find the best question to split a (subset of a) dataset, or\n","- if it is a leaf node, predict an output.\n","\n","To find the best question for one feature, compute all the **midpoints** of that feature, and for each midpoint, compute the entropy of the resulting split when the question uses that midpoint. To find the best question overall, repeat this for all columns, and pick the best question.\n","\n","For example, let's say you have this dataset:\n","\n","```\n","array([[ 0.94, -1.45, -0.1 ,  1.26],\n","       [-0.4 ,  0.94,  0.69,  1.53],\n","       [-0.38, -0.53,  1.85, -0.89]])\n","```\n","\n","The second column has the values `-1.45, 0.94, -0.53`. Sorting these values gives us `-1.45, -0.53,  0.94`. If we take the midpoints of these values, we get `-0.99, 0.21`.\n","\n","/\n","\n","Impl√©mentons une classe **Node** (noeud) √† utiliser dans l'arbre de d√©cision. Un noeud dans l'arbre peut:\n","\n","* poser une question (= determiner si les exemples ont un certain attribut plus grand qu'un certain seuil),\n","* trouver la meilleure question pour s√©parer un (sous-ensemble d'un) jeu de donn√©es, ou\n","* si c'est une feuille, faire une pr√©diction\n","\n","Pour trouver la meilleure question pour un attribut, calculer tout les **valeurs interm√©diaires** de cet attribut, et pour chaque valeur interm√©diaire, calculer l'entropie de la s√©paration obtenue quand la question utilise cette valeur interm√©diaire. Pour trouver la meilleur question, r√©peter √ßa pour chaque colonne, et choisir la meilleur question.\n","\n","Par exemple, disons que vous ayez ce jeu de donn√©es:\n","\n","```\n","array([[ 0.94, -1.45, -0.1 ,  1.26],\n","       [-0.4 ,  0.94,  0.69,  1.53],\n","       [-0.38, -0.53,  1.85, -0.89]])\n","```\n","\n","La deuxi√®me colonne a les valeurs `-1.45, 0.94, -0.53`. Trier ces valeurs nous donne `-1.45, -0.53, 0.94`. Si nous prenons les valeurs interm√©diaires, nous obtenons `-0.99, 0.21`."]},{"cell_type":"code","metadata":{"id":"LOcjyw1AglQ8","colab_type":"code","outputId":"b84f4745-7ac8-49b1-cbe9-4911a9d84a42","executionInfo":{"status":"ok","timestamp":1573699703224,"user_tz":300,"elapsed":383,"user":{"displayName":"Ioannis Mitliagkas","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mARrYotv-n8ZDKjMjlKZFJrnBCnATEt_QFIq0GBMw=s64","userId":"10798961238703719281"}},"colab":{"base_uri":"https://localhost:8080/","height":69}},"source":["class Node():\n","    def __init__(self):\n","        self.threshold = None\n","        self.col = None\n","        self.is_leaf = None\n","        self.output_class = None\n","        self.left_child=None\n","        self.right_child=None\n","        \n","    def find_best_question(self, x, y):\n","        # x: np array of shape (number of examples, number of features)\n","        # y: np array of shape (number of examples,)\n","        #\n","        # x: tableau numpy de dimension (nombre d'exemples, nombre d'attributs)\n","        # y: tableau numpy de dimension (nombre d'exemples,)\n","        best_col = 0\n","        best_val = 0\n","        best_loss = np.inf\n","        \n","        num_cols = x.shape[1]\n","        valid_cols = np.arange(num_cols)\n","        for col in valid_cols:\n","            #\n","            # Compute the midpoints of this column's values here\n","            #\n","            # Calculer les valeurs interm√©diaires de cette colonne ici\n","            #\n","            midpoints=[]\n","            for val in midpoints:\n","                #\n","                # Using col and val, split the labels\n","                # into left_labels, right_labels here\n","                #\n","                # En utilisant col et val, s√©parer les labels\n","                # en left_labels (labels_gauches) et right_labels\n","                # (labels_droits) ici\n","                #\n","                \n","                right_entropy = compute_entropy(right_labels)\n","                left_entropy = compute_entropy(left_labels)\n","                loss = left_entropy + right_entropy\n","                if right_labels.shape[0] == 0 or left_labels.shape[0] == 0:\n","                    continue\n","                \n","                if loss < best_loss:\n","                    best_loss = loss\n","                    best_col = col\n","                    best_val = val\n","                    \n","        self.col = best_col\n","        self.threshold = best_val\n","    \n","    def ask_question(self, x):\n","        if not self.is_leaf:\n","            return x[:, self.col] > self.threshold\n","        else:\n","            print(\"Error: leaf nodes cannot ask questions!\")\n","            return False\n","    \n","    def predict(self):\n","        if self.is_leaf:\n","            return self.output_class\n","        else:\n","            print(\"Error: non-leaf nodes cannot make a prediction!\")\n","            return None\n","\n","node=Node()\n","example_x = np.array([[-2.32,  2.02,  0.53,  0.34],\n","       [-1.44,  1.36,  0.12, -0.44],\n","       [-0.28, -0.08,  0.9 , -1.63],\n","       [-0.09,  0.17, -0.28,  0.44],\n","       [ 0.8 , -1.65,  1.36,  1.62]])\n","example_y = np.array([3,1,2,0,2])\n","\n","# Test find_best_question()\n","node.find_best_question(example_x, example_y)\n","print(node.threshold) # should be -1.88\n","print(node.col) # should be 0\n","\n","# Test ask_question()\n","test_x = np.array([[ 1.05, -1.85, -2.24,  1.45],\n","       [ 1.2 , -0.34,  1.54, -0.39]])\n","print(node.ask_question(test_x)) # should be [True True]"],"execution_count":0,"outputs":[{"output_type":"stream","text":["0\n","0\n","[ True  True]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"yXVWLTatglQ-","colab_type":"text"},"source":["Now, using the Node class, we will implement the decision tree. Like scikit-learn's interface, we will have fit() and predict() methods.\n","\n","/\n","\n","Maintenant, en utilisant la classe Node, nous allons impl√©menter l'arbre de d√©cision. Comme avec l'interface de scikit-learn, nous aurons les m√©thodes fit() et predict()."]},{"cell_type":"code","metadata":{"id":"8tHisDwBgnsH","colab_type":"code","colab":{}},"source":["class DecisionTreeClassifier():\n","    def __init__(self, max_depth=1):\n","        self.max_depth = max_depth\n","    \n","    def create_node(self, x_subset, y_subset, depth):\n","        # Recursive function\n","        node = Node()\n","        \n","        majority_class = get_majority_class(y_subset)\n","        majority_class_count = (y_subset == majority_class).sum()\n","        perfectly_classified = majority_class_count == len(y_subset)\n","        \n","        if perfectly_classified or depth == self.max_depth:\n","            node.output_class = majority_class\n","            node.is_leaf = True\n","        else:\n","            node.find_best_question(x_subset,y_subset)\n","            node.is_leaf = False\n","            right_subset_rows = node.ask_question(x_subset) \n","            left_subset_rows = np.invert(right_subset_rows)\n","            #\n","            # Recursion: create node.left_child and node.right_child here\n","            #\n","            # R√©cursion: cr√©er node.left_child (enfant gauche du noeud) et\n","            # node.right_child (enfant droit du noeud) ici\n","            #\n","                \n","        return node\n","    \n","    def fit(self, x, y):\n","        self.root_node = self.create_node(x,y,depth=1)\n","    \n","    def predict(self, x):\n","        predictions = []\n","        \n","        for i in range(len(x)):\n","            current_node = self.root_node\n","            x_i = x[i].reshape(1,-1)\n","            done_descending_tree = False\n","            while not done_descending_tree:\n","                if current_node.is_leaf:\n","                    predictions.append(current_node.predict())\n","                    done_descending_tree = True\n","\n","                else:\n","                    if current_node.ask_question(x_i):\n","                        current_node = current_node.right_child\n","                    else:\n","                        current_node = current_node.left_child\n","\n","        return np.array(predictions)\n","        "],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Ntcx_HhmglRA","colab_type":"text"},"source":["Train a tree to test your implementation. (You can also try comparing with scikit-learn's tree implementation.)\n","\n","/\n","\n","Entrainez un arbre pour tester votre impl√©mentation. (Vous pouvez aussi essayer de comparer avec l'impl√©mentation d'arbre de scikit-learn.)"]},{"cell_type":"code","metadata":{"id":"QCUMQEbcglRB","colab_type":"code","outputId":"c6d1165f-bf64-4898-9b88-48dd124fbd94","executionInfo":{"status":"error","timestamp":1573699707635,"user_tz":300,"elapsed":373,"user":{"displayName":"Ioannis Mitliagkas","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mARrYotv-n8ZDKjMjlKZFJrnBCnATEt_QFIq0GBMw=s64","userId":"10798961238703719281"}},"colab":{"base_uri":"https://localhost:8080/","height":390}},"source":["# import sklearn.tree\n","# tree = sklearn.tree.DecisionTreeClassifier(max_depth=10)\n","tree = DecisionTreeClassifier(max_depth=10)\n","tree.fit(iris_train_x, iris_train_y)\n","print(iris_test_y)\n","print(tree.predict(iris_test_x))\n","print(\"accuracy: \", (tree.predict(iris_test_x) == iris_test_y).mean() * 100, \"%\")"],"execution_count":0,"outputs":[{"output_type":"stream","text":["[1 0 0 1 2 0 2 1 2 2 1 2 0 2 1 1 0 2 2 2 0 0 0 0 2 1 2 1 1 0 2 2 1 0 1 0 1\n"," 2 1 2 0 0 1 1 0 0 0 2 0 1 1 0 2 0 0 1 1 0 1 1 2 1 1 2 2 0 2 1 0 1 0 1 2 1\n"," 0 1 0 1 0 1 1 0 0 2 2 1 0 1 2 1 0 0 0 2 2 1 2 1 0 1]\n"],"name":"stdout"},{"output_type":"error","ename":"AttributeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-5-1e478fd2c2e0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miris_train_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miris_train_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miris_test_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miris_test_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"accuracy: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miris_test_x\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0miris_test_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"%\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-4-615ae0722817>\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[0mdone_descending_tree\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdone_descending_tree\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m                 \u001b[0;32mif\u001b[0m \u001b[0mcurrent_node\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_leaf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m                     \u001b[0mpredictions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurrent_node\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m                     \u001b[0mdone_descending_tree\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'is_leaf'"]}]},{"cell_type":"markdown","metadata":{"id":"kdv6a36lglRD","colab_type":"text"},"source":["Train trees of increasing depth on the Iris dataset and plot their performance. What do you notice about the performance as the depth increases?\n","\n","/\n","\n","Entrainez des arbres de profondeur croissante sur le jeu de donn√©es Iris et tracez leurs performances. Que remarquez-vous sur les performances lorsque la profondeur augmente ?"]},{"cell_type":"code","metadata":{"id":"_t-gEoadglRE","colab_type":"code","outputId":"377017d9-b846-447f-8423-3613a89013c6","executionInfo":{"status":"error","timestamp":1573598868957,"user_tz":300,"elapsed":855,"user":{"displayName":"R√©mi Le Priol","photoUrl":"","userId":"06369136232577523795"}},"colab":{"base_uri":"https://localhost:8080/","height":355}},"source":["depths = []\n","accuracies = []\n","for depth in range(1, 20):\n","    model = DecisionTreeClassifier(max_depth=depth)\n","    model.fit(iris_train_x, iris_train_y)\n","    accuracy = (model.predict(iris_test_x) == iris_test_y).mean()\n","    accuracies.append(accuracy)\n","    depths.append(depth)\n","\n","print(\"Best performance: \", max(accuracies))\n","plt.xlabel('Tree depth')\n","plt.ylabel('Performance on test set')\n","plt.plot(depths, accuracies)"],"execution_count":0,"outputs":[{"output_type":"error","ename":"AttributeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-17-878fd62acad5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDecisionTreeClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_depth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdepth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miris_train_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miris_train_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miris_test_x\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0miris_test_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0maccuracies\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mdepths\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdepth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-15-615ae0722817>\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[0mdone_descending_tree\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdone_descending_tree\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m                 \u001b[0;32mif\u001b[0m \u001b[0mcurrent_node\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_leaf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m                     \u001b[0mpredictions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurrent_node\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m                     \u001b[0mdone_descending_tree\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'is_leaf'"]}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"ayoDSZJWglRH"},"source":["## Random forest\n","\n","Next, we will implement the random forest model using our decision tree. \n","\n","A random forest is an ensemble of decision trees, where each tree is trained by randomizing the dataset. The standard method for randomizing the dataset is feature bagging, where a random subset of features is selected for each tree, but other methods are possible.\n","\n","We will explore two ways of randomizing the dataset: 1) feature bagging, and 2) example bagging, i.e. training each classifier on a random subset of the dataset.\n","\n","/\n","\n","## For√™t al√©atoire\n","Ensuite, nous allons impl√©menter une for√™t al√©atoire en utilisant notre arbre de d√©cision.\n","\n","Une for√™t al√©atoire est un ensemble d'arbres de d√©cision, o√π chaque arbre est entrain√© sur une variation al√©atoire du jeu de donn√©es. La m√©thode standard pour obtenir ces variations est le feature bagging (ensachage d'attributs), o√π un sous-ensemble al√©atoire des attributs est choisi pour chaque arbre, mais d'autres m√©thodes sont possibles.\n","\n","Nous allons explorer deux fa√ßon d'obtenir des variations al√©atoires du jeu de donn√©es: 1) feature bagging (ensachage d'attributs), et 2) example bagging (ensachage d'exemples), i.e. entrainer chaque classifieur sur un sous-ensemble al√©atoire du jeu de donn√©es."]},{"cell_type":"code","metadata":{"id":"gwIddcEZglRI","colab_type":"code","colab":{}},"source":["import math\n","\n","class RandomForestClassifier():\n","    def __init__(self, n_estimators=2, max_depth=5, bootstrap_fraction=0.5, features_fraction=0.5):\n","        self.max_depth = max_depth\n","        self.n_estimators = n_estimators\n","        self.bootstrap_fraction = bootstrap_fraction\n","        self.features_fraction= features_fraction\n","        self.estimators = []\n","        \n","    def fit(self, x, y):\n","        num_rows = math.ceil(self.bootstrap_fraction * x.shape[0])\n","        num_cols = math.ceil(self.features_fraction * x.shape[1])\n","        for _ in range(self.n_estimators):\n","            rows_idx = np.random.choice(x.shape[0], size=num_rows)\n","            cols_idx = np.random.choice(x.shape[1], size=num_cols, replace=False)\n","            # \n","            # Create noisy subsets x_subset, y_subset here\n","            # \n","            # Cr√©er ici les sous-ensembles al√©atoires x_subset, y_subset\n","            # \n","            x_subset, y_subset = [], []\n","            tree = DecisionTreeClassifier(max_depth=self.max_depth)\n","            tree.fit(x_subset, y_subset)\n","            self.estimators.append((tree,cols_idx))\n","        \n","    def predict(self, x):\n","        #\n","        # Predict output using all estimators here\n","        # \n","        # Faire une pr√©diction se basant sur tout les estimateurs ici\n","        # \n","        pass\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"RWGCu0IBglRK","colab_type":"text"},"source":["Now let's look at the influence of these hyperparameters. First, let's plot the performance as a function of the number of trees when using feature bagging only. Next, let's try example bagging only. Then let's put them together.\n","\n","/\n","\n","Maintenant regardons l'influence de ces hyperparam√®tres. D'abord, tra√ßons les performances en fonction du nombre d'arbres en utilisant uniquement le feature bagging (ensachage d'attributs). Ensuite, essayons l'example bagging (ensachage d'exemples). Finalement, combinons-les ensemble.\n","\n"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"My2jcUPk2SpA","scrolled":true,"colab":{}},"source":["def validation_curve(bootstrap_fraction, features_fraction):\n","  tree_counts = []\n","  accuracies = []\n","  for tree_count in range(1, 20):\n","      model = RandomForestClassifier(n_estimators=tree_count,\n","                                    max_depth=3,\n","                                    bootstrap_fraction=bootstrap_fraction,\n","                                    features_fraction=features_fraction)\n","      model.fit(iris_train_x, iris_train_y)\n","      accuracy = (model.predict(iris_test_x) == iris_test_y).mean()\n","      accuracies.append(accuracy)\n","      tree_counts.append(tree_count)\n","\n","  print(\"Best performance: \", max(accuracies))\n","  plt.xlabel('n_estimators')\n","  plt.ylabel('Performance on test set')\n","  plt.plot(tree_counts, accuracies)\n","  plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"0nPtGKtd2SpQ","outputId":"65b54dce-98ab-41dd-acb3-faa21dd73c92","executionInfo":{"status":"error","timestamp":1573598887374,"user_tz":300,"elapsed":512,"user":{"displayName":"R√©mi Le Priol","photoUrl":"","userId":"06369136232577523795"}},"colab":{"base_uri":"https://localhost:8080/","height":310}},"source":["validation_curve(0.5,1)"],"execution_count":0,"outputs":[{"output_type":"error","ename":"AttributeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-23-213900f1c456>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mvalidation_curve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-22-579b3cb55532>\u001b[0m in \u001b[0;36mvalidation_curve\u001b[0;34m(bootstrap_fraction, features_fraction)\u001b[0m\n\u001b[1;32m      7\u001b[0m                                     \u001b[0mbootstrap_fraction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbootstrap_fraction\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m                                     features_fraction=features_fraction)\n\u001b[0;32m----> 9\u001b[0;31m       \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miris_train_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miris_train_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m       \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miris_test_x\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0miris_test_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m       \u001b[0maccuracies\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-21-30e083b74527>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y)\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0mx_subset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_subset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0mtree\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDecisionTreeClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_depth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m             \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_subset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_subset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimators\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtree\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcols_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-15-615ae0722817>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot_node\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_node\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdepth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-15-615ae0722817>\u001b[0m in \u001b[0;36mcreate_node\u001b[0;34m(self, x_subset, y_subset, depth)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mmajority_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_majority_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_subset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mmajority_class_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0my_subset\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mmajority_class\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0mperfectly_classified\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmajority_class_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_subset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: 'bool' object has no attribute 'sum'"]}]},{"cell_type":"code","metadata":{"id":"ZS_GrfFgglRR","colab_type":"code","outputId":"4844c486-03f2-4108-de83-ee26f9e894fd","executionInfo":{"status":"error","timestamp":1573598909076,"user_tz":300,"elapsed":537,"user":{"displayName":"R√©mi Le Priol","photoUrl":"","userId":"06369136232577523795"}},"colab":{"base_uri":"https://localhost:8080/","height":310}},"source":["validation_curve(1, 0.5)"],"execution_count":0,"outputs":[{"output_type":"error","ename":"AttributeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-24-213900f1c456>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mvalidation_curve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-22-579b3cb55532>\u001b[0m in \u001b[0;36mvalidation_curve\u001b[0;34m(bootstrap_fraction, features_fraction)\u001b[0m\n\u001b[1;32m      7\u001b[0m                                     \u001b[0mbootstrap_fraction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbootstrap_fraction\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m                                     features_fraction=features_fraction)\n\u001b[0;32m----> 9\u001b[0;31m       \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miris_train_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miris_train_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m       \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miris_test_x\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0miris_test_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m       \u001b[0maccuracies\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-21-30e083b74527>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y)\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0mx_subset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_subset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0mtree\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDecisionTreeClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_depth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m             \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_subset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_subset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimators\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtree\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcols_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-15-615ae0722817>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot_node\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_node\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdepth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-15-615ae0722817>\u001b[0m in \u001b[0;36mcreate_node\u001b[0;34m(self, x_subset, y_subset, depth)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mmajority_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_majority_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_subset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mmajority_class_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0my_subset\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mmajority_class\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0mperfectly_classified\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmajority_class_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_subset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: 'bool' object has no attribute 'sum'"]}]},{"cell_type":"code","metadata":{"id":"e_gitj5czc_a","colab_type":"code","colab":{}},"source":["validation_curve(.5,.5)"],"execution_count":0,"outputs":[]}]}